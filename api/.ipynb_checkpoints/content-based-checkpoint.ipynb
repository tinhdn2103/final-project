{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c428b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pymongo import MongoClient\n",
    "import pickle\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['movie-web']\n",
    "col_movies = db['movies']\n",
    "cur_movies = col_movies.find()\n",
    "col_actormovies = db['actormovies']\n",
    "cur_actormovies = col_actormovies.find()\n",
    "col_actors = db['actors']\n",
    "cur_actors = col_actors.find()\n",
    "list_movies = []\n",
    "list_actormovies = []\n",
    "list_actors = []\n",
    "for i in cur_movies:\n",
    "    list_movies.append(i)\n",
    "for i in cur_actormovies:\n",
    "    list_actormovies.append(i)\n",
    "for i in cur_actors:\n",
    "    list_actors.append(i)\n",
    "movies = pd.DataFrame(list_movies)\n",
    "actormovies = pd.DataFrame(list_actormovies)\n",
    "actors = pd.DataFrame(list_actors)\n",
    "movies = movies.drop(['img', 'imgTitle', 'createdAt', 'updatedAt', 'trailer', 'year', 'limit', 'isSeries', '__v', 'numRate', 'rate', 'duration', 'countView', 'epNum'], axis=1)\n",
    "\n",
    "df = pd.merge(actormovies[['movie', 'actor', 'character']],actors[['_id','name']],left_on='actor', right_on='_id', how='left').drop(columns = ['_id'])\n",
    "df2 = pd.merge(movies, df, left_on='_id', right_on='movie', how='left').drop(columns = ['movie', 'actor'])\n",
    "df2 = df2.fillna('')\n",
    "df2 = df2.groupby('_id').agg({'title':'first', \n",
    "                              'desc':'first',\n",
    "                              'genre':'first',\n",
    "                             'character': ' '.join, \n",
    "                             'name': ' '.join,  }).reset_index()\n",
    "\n",
    "df2['tags'] = df2['title'] + ' ' + df2['desc'] + ' ' + df2['genre'] + ' ' + df2['character'] + ' ' + df2['name']\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df2['tags'])\n",
    "\n",
    "with open('vectorizer.pk', 'wb') as fin:\n",
    "    pickle.dump(tfidf, fin)\n",
    "    pickle.dump(tfidf_matrix, fin)\n",
    "    pickle.dump(df2['_id'], fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dec90f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    633dc3b4f611a788116b43d8\n",
       "1    633dc52cf611a788116b43dc\n",
       "2    633dd3e4f611a788116b43e7\n",
       "3    6354e362c834f95698ef0221\n",
       "4    6354ebb6c834f95698ef02ca\n",
       "5    6354ec56c834f95698ef02cd\n",
       "6    637a48a12d686b1096842328\n",
       "Name: _id, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pickle\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import sparse\n",
    "\n",
    "with open('vectorizer.pk', 'rb') as fin:\n",
    "    vectorizer = pickle.load(fin)\n",
    "    matrix_tfidf = pickle.load(fin)\n",
    "    df = pickle.load(fin)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46eff35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doctor Strange',\n",
       " 'Doctor Strange in Multiverse of Madness',\n",
       " 'Death on the Nile',\n",
       " 'Nope',\n",
       " 'Stranger Things 4',\n",
       " 'Inside Out',\n",
       " 'Coco']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_recommendations(title):\n",
    "\n",
    "#     df3 = pd.concat([df2['tags'], pd.Series([title])], ignore_index = True)\n",
    "    \n",
    "#     tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#     tfidf_matrix = tfidf.fit_transform(df3)\n",
    "    \n",
    "#     cosine_sim = linear_kernel(tfidf_matrix[df3.index.max()], tfidf_matrix)\n",
    "    \n",
    "#     sim_scores = list(enumerate(cosine_sim[0]))\n",
    "#     sim_scores = sim_scores[:-1]\n",
    "#     sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     sim_scores = sim_scores[0:10]\n",
    "\n",
    "#     movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "#     return df2['title'].iloc[movie_indices].astype('string')\n",
    "\n",
    "# list(get_recommendations('hoạt hình'))\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pickle\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import sparse\n",
    "\n",
    "with open('vectorizer.pk', 'rb') as fin:\n",
    "    vectorizer = pickle.load(fin)\n",
    "    matrix_tfidf = pickle.load(fin)\n",
    "    df = pickle.load(fin)\n",
    "\n",
    "def get_recommendations(title):\n",
    "    m_new = sparse.vstack((matrix_tfidf, vectorizer.transform([title])))\n",
    "    svd = TruncatedSVD(n_components=10)\n",
    "    svd.fit(m_new)\n",
    "    svd_tfidf_vector = svd.transform(m_new)\n",
    "    svd_query = np.reshape(svd_tfidf_vector[-1],(1,svd_tfidf_vector[-1].size))\n",
    "    cosine_sim = linear_kernel(svd_query, svd_tfidf_vector)\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    sim_scores = sim_scores[:-1]\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[0:10]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return df2['title'].iloc[movie_indices].astype('string')\n",
    "list(get_recommendations('Benedict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a7dd045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633dc3b4f611a788116b43d8</td>\n",
       "      <td>633e8ba2bc3a40391db45a5c</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633dc3b4f611a788116b43d8</td>\n",
       "      <td>633e900bbc3a40391db45a7f</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633dc52cf611a788116b43dc</td>\n",
       "      <td>633b30e4edfee7840d1006c6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633dc52cf611a788116b43dc</td>\n",
       "      <td>633e8ba2bc3a40391db45a5c</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633dd3e4f611a788116b43e7</td>\n",
       "      <td>633e8ba2bc3a40391db45a5c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>633dd3e4f611a788116b43e7</td>\n",
       "      <td>633b30e4edfee7840d1006c6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>633dc52cf611a788116b43dc</td>\n",
       "      <td>633e900bbc3a40391db45a7f</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6354ebb6c834f95698ef02ca</td>\n",
       "      <td>633e8ba2bc3a40391db45a5c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6354ec56c834f95698ef02cd</td>\n",
       "      <td>633e8ba2bc3a40391db45a5c</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      movie                      user  rating\n",
       "0  633dc3b4f611a788116b43d8  633e8ba2bc3a40391db45a5c       5\n",
       "1  633dc3b4f611a788116b43d8  633e900bbc3a40391db45a7f       5\n",
       "2  633dc52cf611a788116b43dc  633b30e4edfee7840d1006c6       4\n",
       "3  633dc52cf611a788116b43dc  633e8ba2bc3a40391db45a5c       5\n",
       "4  633dd3e4f611a788116b43e7  633e8ba2bc3a40391db45a5c       2\n",
       "5  633dd3e4f611a788116b43e7  633b30e4edfee7840d1006c6       2\n",
       "6  633dc52cf611a788116b43dc  633e900bbc3a40391db45a7f       3\n",
       "7  6354ebb6c834f95698ef02ca  633e8ba2bc3a40391db45a5c       2\n",
       "8  6354ec56c834f95698ef02cd  633e8ba2bc3a40391db45a5c       5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userratings = db['userratings']\n",
    "cursor = userratings.find()\n",
    "list_cur = []\n",
    "for i in cursor:\n",
    "    list_cur.append(i)\n",
    "ratings = pd.DataFrame(list_cur)\n",
    "ratings = ratings.drop(['_id', '__v', 'createdAt', 'updatedAt'], axis=1)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6a2f36f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    633dc3b4f611a788116b43d8\n",
       " 3    633dc52cf611a788116b43dc\n",
       " 4    633dd3e4f611a788116b43e7\n",
       " 7    6354ebb6c834f95698ef02ca\n",
       " 8    6354ec56c834f95698ef02cd\n",
       " Name: movie, dtype: string,\n",
       " 0    5\n",
       " 3    5\n",
       " 4    2\n",
       " 7    2\n",
       " 8    5\n",
       " Name: rating, dtype: int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_items_rated_by_user(user_id):\n",
    "    y = ratings.iloc[:,1].astype('string')\n",
    "    ids = np.where(y == user_id)[0]\n",
    "    item_ids = ratings.iloc[ids, 0].astype('string')\n",
    "    scores = ratings.iloc[ids, 2]\n",
    "    return (item_ids, scores)\n",
    "get_items_rated_by_user('633e8ba2bc3a40391db45a5c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fba7d792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.8106122 4.        3.       ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.4053061 , 4.5       , 3.        ],\n",
       "       [4.4053061 , 3.5       , 3.5       ],\n",
       "       [2.9053061 , 4.        , 2.5       ],\n",
       "       [3.90426896, 4.07874366, 3.        ],\n",
       "       [2.96929883, 4.        , 3.        ],\n",
       "       [4.31478287, 4.        , 3.        ],\n",
       "       [3.17010554, 4.        , 2.64624857]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "svd = TruncatedSVD(n_components=10)\n",
    "svd.fit(matrix_tfidf)\n",
    "svd_tfidf_vector = svd.transform(matrix_tfidf)\n",
    "d = svd_tfidf_vector.shape[1] \n",
    "users = ratings['user'].astype('string').unique()\n",
    "W = np.zeros((d, users.size))\n",
    "b = np.zeros((1, users.size))\n",
    "# df = pd.DataFrame(df)\n",
    "for idx, n in enumerate(users):    \n",
    "    ids, scores = get_items_rated_by_user(n)\n",
    "    clf = Ridge(alpha = 1, fit_intercept  = True)\n",
    "    ids_items = df[df.astype('string').isin(ids)].index.tolist()\n",
    "    Xhat = svd_tfidf_vector[ids_items, :]\n",
    "    clf.fit(Xhat, scores) \n",
    "    W[:, idx] = clf.coef_\n",
    "    b[0, idx] = clf.intercept_\n",
    "print(b)\n",
    "Yhat = svd_tfidf_vector.dot(W) + b\n",
    "# print(Yhat)\n",
    "# Yhat = svd_tfidf_vector.dot(W) + b\n",
    "Yhat\n",
    "# with open('model_content_based.pk', 'wb') as fin:\n",
    "#     pickle.dump(Yhat, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149940e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ad81968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633e8ba2bc3a40391db45a5c</td>\n",
       "      <td>6354e362c834f95698ef0221</td>\n",
       "      <td>3.826332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633e8ba2bc3a40391db45a5c</td>\n",
       "      <td>637a48a12d686b1096842328</td>\n",
       "      <td>3.643331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633e900bbc3a40391db45a7f</td>\n",
       "      <td>6354e362c834f95698ef0221</td>\n",
       "      <td>4.019686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633e900bbc3a40391db45a7f</td>\n",
       "      <td>633dd3e4f611a788116b43e7</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633e900bbc3a40391db45a7f</td>\n",
       "      <td>6354ebb6c834f95698ef02ca</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633e900bbc3a40391db45a7f</td>\n",
       "      <td>6354ec56c834f95698ef02cd</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633e900bbc3a40391db45a7f</td>\n",
       "      <td>637a48a12d686b1096842328</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633b30e4edfee7840d1006c6</td>\n",
       "      <td>633dc3b4f611a788116b43d8</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633b30e4edfee7840d1006c6</td>\n",
       "      <td>6354e362c834f95698ef0221</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633b30e4edfee7840d1006c6</td>\n",
       "      <td>6354ebb6c834f95698ef02ca</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>633b30e4edfee7840d1006c6</td>\n",
       "      <td>6354ec56c834f95698ef02cd</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633b30e4edfee7840d1006c6</td>\n",
       "      <td>637a48a12d686b1096842328</td>\n",
       "      <td>2.911562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     userId                   movieId     score\n",
       "0  633e8ba2bc3a40391db45a5c  6354e362c834f95698ef0221  3.826332\n",
       "1  633e8ba2bc3a40391db45a5c  637a48a12d686b1096842328  3.643331\n",
       "0  633e900bbc3a40391db45a7f  6354e362c834f95698ef0221  4.019686\n",
       "1  633e900bbc3a40391db45a7f  633dd3e4f611a788116b43e7  4.000000\n",
       "2  633e900bbc3a40391db45a7f  6354ebb6c834f95698ef02ca  4.000000\n",
       "3  633e900bbc3a40391db45a7f  6354ec56c834f95698ef02cd  4.000000\n",
       "4  633e900bbc3a40391db45a7f  637a48a12d686b1096842328  4.000000\n",
       "0  633b30e4edfee7840d1006c6  633dc3b4f611a788116b43d8  3.000000\n",
       "1  633b30e4edfee7840d1006c6  6354e362c834f95698ef0221  3.000000\n",
       "2  633b30e4edfee7840d1006c6  6354ebb6c834f95698ef02ca  3.000000\n",
       "3  633b30e4edfee7840d1006c6  6354ec56c834f95698ef02cd  3.000000\n",
       "4  633b30e4edfee7840d1006c6  637a48a12d686b1096842328  2.911562"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = ratings['movie'].astype('string').unique()\n",
    "def recommend(user_id, top):\n",
    "    item = {'userId': None, 'movieId': None, 'score': None}\n",
    "    list_items = []\n",
    "    def take_score(elem):\n",
    "        return elem['score']\n",
    "    items_rated_by_user, score = get_items_rated_by_user(user_id)\n",
    "    for idx, n in enumerate(df.astype('string')): \n",
    "        if n not in items_rated_by_user.tolist():\n",
    "            item['userId'] = user_id\n",
    "            item['movieId'] = n\n",
    "            item['score'] = Yhat[idx, np.where(users == user_id)[0][0]]\n",
    "            list_items.append(item.copy())  \n",
    "    sorted_items = sorted(list_items, key=take_score, reverse=True)\n",
    "    sorted_items = sorted_items[:top]\n",
    "    return sorted_items\n",
    "df3 = pd.DataFrame(columns=['userId', 'movieId', 'score'])\n",
    "for u in users:\n",
    "    df3 = pd.concat([df3, pd.DataFrame(recommend(u, 10))])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e4deda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 5 4 2 1 0]\n",
      "[{'userId': '633e900bbc3a40391db45a7f', 'movieId': '6354e362c834f95698ef0221', 'score': 4.019685915439231}, {'userId': '633e900bbc3a40391db45a7f', 'movieId': '633dd3e4f611a788116b43e7', 'score': 4.0}, {'userId': '633e900bbc3a40391db45a7f', 'movieId': '6354ebb6c834f95698ef02ca', 'score': 4.0}, {'userId': '633e900bbc3a40391db45a7f', 'movieId': '6354ec56c834f95698ef02cd', 'score': 4.0}, {'userId': '633e900bbc3a40391db45a7f', 'movieId': '637a48a12d686b1096842328', 'score': 4.0}]\n"
     ]
    }
   ],
   "source": [
    "items = ratings['movie'].astype('string').unique()\n",
    "a = np.zeros((df.size,))\n",
    "recommended_items = []\n",
    "items_rated_by_user, score = get_items_rated_by_user('633e900bbc3a40391db45a7f')\n",
    "item = {'userId': None, 'movieId': None, 'score': None}\n",
    "list_items = []\n",
    "def take_score(elem):\n",
    "    return elem['score']\n",
    "for idx, n in enumerate(df.astype('string')): \n",
    "    if n not in items_rated_by_user.tolist():\n",
    "        item['userId'] = '633e900bbc3a40391db45a7f'\n",
    "        item['movieId'] = n\n",
    "        item['score'] = Yhat[idx, np.where(users == '633e900bbc3a40391db45a7f')[0][0]]\n",
    "        a[idx] = Yhat[idx, np.where(users == '633e900bbc3a40391db45a7f')[0][0]]\n",
    "        list_items.append(item.copy())  \n",
    "sorted_items = sorted(list_items, key=take_score, reverse=True)\n",
    "sorted_items = sorted_items[:10]\n",
    "recommended_items = np.argsort(a)[-10:][::-1]\n",
    "print(recommended_items)\n",
    "df2['title'].iloc[recommended_items]\n",
    "print(sorted_items)\n",
    "# df3 = pd.DataFrame(columns=['userId', 'movieId', 'similar'])\n",
    "# users = df_std.columns.tolist()\n",
    "# for u in users:\n",
    "#     df = pd.concat([df, pd.DataFrame(recommend_top(u, 10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c38da6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['6354e362c834f95698ef0221', '633dd3e4f611a788116b43e7', '6354ebb6c834f95698ef02ca', '6354ec56c834f95698ef02cd', '637a48a12d686b1096842328']\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "recommend = pd.read_csv('recommendCB.csv')\n",
    "ids = np.where(recommend.iloc[:, 0] == '633e900bbc3a40391db45a7f')[0]\n",
    "movies = recommend.iloc[ids, 1].tolist()\n",
    "# sys.stdout.write(str(movies))\n",
    "str(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9850164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pymongo import MongoClient\n",
    "from underthesea import word_tokenize\n",
    "import pickle\n",
    "from bson import ObjectId\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "\n",
    "class CB:\n",
    "    def __init__(self):\n",
    "        client = MongoClient('mongodb://localhost:27017/')\n",
    "        db = client['movie-web']\n",
    "        self.col_m = db.movies\n",
    "        self.col_am = db.actormovies\n",
    "        self.col_a = db.actors\n",
    "        self.col_ur = db.userratings\n",
    "        \n",
    "    def get_items_rated_by_user(self, u):\n",
    "        y = self.ratings.iloc[:,1]\n",
    "        ids = np.where(y == u)[0]\n",
    "        item_ids = self.ratings.iloc[ids, 0]\n",
    "        scores = self.ratings.iloc[ids, 2]\n",
    "        return (item_ids, scores)\n",
    "    \n",
    "    def fit(self):\n",
    "        cur_m = self.col_m.find({}, {\"title\": 1, \"desc\": 1, \"genre\": 1})\n",
    "        cur_am = self.col_am.find({}, {\"movie\": 1, \"actor\": 1, \"character\": 1, \"_id\": 0})\n",
    "        cur_a = self.col_a.find({}, {\"name\": 1})\n",
    "        cur_ur = self.col_ur.find({}, {\"movie\": 1, \"user\": 1, \"rating\": 1, \"_id\": 0})\n",
    "        list_ur = []\n",
    "        list_m = []\n",
    "        list_am = []\n",
    "        list_a = []\n",
    "        for i in cur_ur:\n",
    "            list_ur.append(i)\n",
    "        self.ratings = pd.DataFrame(list_ur)\n",
    "        \n",
    "        for i in cur_m:\n",
    "            list_m.append(i)\n",
    "        for i in cur_am:\n",
    "            list_am.append(i)\n",
    "        for i in cur_a:\n",
    "            list_a.append(i)\n",
    "        m = pd.DataFrame(list_m)\n",
    "        am= pd.DataFrame(list_am)\n",
    "        a = pd.DataFrame(list_a)\n",
    "        \n",
    "        df = pd.merge(am, a, left_on='actor', right_on='_id', how='left').drop(columns = ['_id', 'actor'])\n",
    "        df2 = pd.merge(m, df, left_on='_id', right_on='movie', how='left').drop(columns = ['movie'])\n",
    "        df2 = df2.fillna('')\n",
    "        df2 = df2.groupby('_id').agg({'title':'first', \n",
    "                              'desc':'first',\n",
    "                              'genre':'first',\n",
    "                              'character': ' '.join, \n",
    "                              'name': ' '.join,  }).reset_index()\n",
    "\n",
    "        df2['tags'] = (df2['title'] + ' ' + df2['desc'] + ' ' + df2['genre'] + ' ' + df2['character'] \n",
    "                       + ' ' + df2['name'])\n",
    "        \n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        self.tfidf_matrix = tfidf.fit_transform(df2['tags'])\n",
    "#         df2['tags'] = df2.apply(lambda row: word_tokenize(row['tags'], format=\"text\"), axis=1)\n",
    "#         stop_words\n",
    "        svd = TruncatedSVD(n_components=10)\n",
    "        vectors = svd.fit_transform(tfidf_matrix)\n",
    "        d = vectors.shape[1] \n",
    "        self.users = self.ratings['user'].unique()\n",
    "        self.movies = df2['_id']\n",
    "        W = np.zeros((d, self.users.size))\n",
    "        b = np.zeros((1, self.users.size))\n",
    "        \n",
    "        for n, u in enumerate(self.users):    \n",
    "            ids, scores = self.get_items_rated_by_user(u)\n",
    "            clf = Ridge(alpha = 1, fit_intercept  = True)\n",
    "            idx = df2[df2['_id'].isin(ids)].index.tolist()\n",
    "            ids_items = df2[df.isin(ids)].index.tolist()\n",
    "            Xhat = vectors[idx, :]\n",
    "            clf.fit(Xhat, scores) \n",
    "            W[:, n] = clf.coef_\n",
    "            b[0, n] = clf.intercept_\n",
    "\n",
    "        Yhat = vectors.dot(W) + b\n",
    "        return Yhat\n",
    "\n",
    "    def recommend_top(self, u, top):\n",
    "        if u in self.users:\n",
    "            item = {'movieId': None, 'score': None}\n",
    "            list_items = []\n",
    "            def take_score(elem):\n",
    "                return elem['score']\n",
    "            ids, score = self.get_items_rated_by_user(u)\n",
    "            for n, m in enumerate(self.movies): \n",
    "                if m not in ids.tolist():\n",
    "                    item['movieId'] = m\n",
    "                    item['score'] = Yhat[n, np.where(self.users == u)[0][0]]\n",
    "                    list_items.append(item.copy())  \n",
    "            sorted_items = sorted(list_items, key=take_score, reverse=True)\n",
    "            sorted_items = sorted_items[:top]\n",
    "            result = []\n",
    "            for i in sorted_items:\n",
    "                result.append(str(i['movieId']))\n",
    "            return result \n",
    "        return []\n",
    "    \n",
    "    def search(self, key):\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        m_new = sparse.vstack((self.tfidf_matrix, tfidf.fit_transform([key])))\n",
    "        svd = TruncatedSVD(n_components=10)\n",
    "        svd_tfidf_vector = svd.fit_transform(m_new)\n",
    "        svd_query = np.reshape(svd_tfidf_vector[-1],(1,svd_tfidf_vector[-1].size))\n",
    "        cosine_sim = linear_kernel(svd_query, svd_tfidf_vector)\n",
    "        sim_scores = list(enumerate(cosine_sim[0]))\n",
    "        sim_scores = sim_scores[:-1]\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[0:10]\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "        return self.movies.iloc[movie_indices].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b237cb77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "The TF-IDF vectorizer is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [140], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cb \u001b[38;5;241m=\u001b[39m CB()\n\u001b[0;32m      2\u001b[0m cb\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDoctor Strange\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [139], line 112\u001b[0m, in \u001b[0;36mCB.search\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m    111\u001b[0m     tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m     m_new \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mvstack((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfidf_matrix, \u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    113\u001b[0m     svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m    114\u001b[0m     svd_tfidf_vector \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(m_new)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2101\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents):\n\u001b[0;32m   2086\u001b[0m     \u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   2087\u001b[0m \n\u001b[0;32m   2088\u001b[0m \u001b[38;5;124;03m    Uses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;124;03m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2101\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe TF-IDF vectorizer is not fitted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2103\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtransform(raw_documents)\n\u001b[0;32m   2104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mtransform(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1345\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1341\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1342\u001b[0m     ]\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"
     ]
    }
   ],
   "source": [
    "cb = CB()\n",
    "cb.fit()\n",
    "cb.search('Doctor Strange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b45fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1c115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "927e6221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455c545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
